{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#jingyu-ning","title":"JingYu Ning","text":"<p>A data scientist focused on artificial intelligence research, currently employed at Delta Electronics, Inc. In my professional field, I specialize in deep learning, machine learning, and semiconductor manufacturing techniques, and I also have experience in ultra-thin film development, ultra-high vacuum technology, and 3D scene reconstruction.</p>"},{"location":"#_1","title":"Home","text":""},{"location":"tags/","title":"Tags","text":""},{"location":"tags/#tags","title":"Tags","text":""},{"location":"tags/#tag:diffusion","title":"Diffusion","text":"<ul> <li>            Diffusion          </li> <li>            VAE          </li> </ul>"},{"location":"tags/#tag:generative-model","title":"Generative Model","text":"<ul> <li>            2025-10-10: Pullback Riemannian Metric          </li> <li>            Diffusion          </li> <li>            RiVAE          </li> <li>            VAE          </li> </ul>"},{"location":"tags/#tag:geodesic","title":"Geodesic","text":"<ul> <li>            RiVAE          </li> </ul>"},{"location":"tags/#tag:manifold","title":"Manifold","text":"<ul> <li>            2025-10-10: Pullback Riemannian Metric          </li> <li>            RiVAE          </li> </ul>"},{"location":"tags/#tag:riemannian-geometry","title":"Riemannian Geometry","text":"<ul> <li>            2025-10-10: Pullback Riemannian Metric          </li> <li>            RiVAE          </li> </ul>"},{"location":"tags/#tag:vae","title":"VAE","text":"<ul> <li>            2025-10-10: Pullback Riemannian Metric          </li> <li>            RiVAE          </li> <li>            VAE          </li> </ul>"},{"location":"posts/","title":"Featured","text":""},{"location":"posts/#blog","title":"Blog","text":""},{"location":"posts/#pullback-riemannian-metric-for-generative-models","title":"Pullback Riemannian Metric for Generative Models","text":"<p>A comprehensive exploration of pullback Riemannian metrics in generative models, detailing their theoretical foundations, computational strategies, and practical applications in machine learning.</p>"},{"location":"posts/pullback_riemannian_metric/","title":"2025-10-10: Pullback Riemannian Metric","text":"","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#pullback-riemannian-metric","title":"Pullback Riemannian Metric","text":"<p>\u5728\u9019\u7bc7\u6587\u7ae0\u4e2d\uff0c\u6211\u6703\u5617\u8a66\u7528\u5f62\u5f0f\u5316\u7684\u65b9\u5f0f\u63cf\u8ff0 pullback Riemannian metric\uff0c \u6574\u7406\u4ed6\u7684\u5e7e\u4f55\u5b9a\u7fa9\u4ee5\u53ca\u5728 VAE/Generative Models \u4e2d\u7684\u89e3\u91cb\uff0c\u540c\u6642\u4f7f\u7528\u5178\u578b\u6559\u8ab2\u66f8\u4f8b\u5b50\u4f86\u88dc\u5145\u8aaa\u660e\u3002</p>","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#1","title":"1. \u76f4\u89c0\u6982\u5ff5","text":"<p>\u7d66\u5b9a\u4e00\u500b\u6620\u5c04 \\(f: \\mathcal{Z} \\to \\mathcal{X}\\) \uff08\u4f8b\u5982 VAE \u4e2d\u7684 decoder\uff09\uff0c \u5728\u8cc7\u6599\u5b58\u5728\u7684\u65bc\u8f38\u51fa\u7a7a\u9593 \\(\\mathcal{X}\\) \u4e2d\uff0c\u6211\u5011\u901a\u5e38\u53ef\u4ee5\u4f7f\u7528\u6a19\u6e96\u6b50\u5e7e\u91cc\u5f97\u5167\u7a4d\u4f86\u5ea6\u91cf\u4e0d\u540c\u7b46\u8cc7\u6599\u4e4b\u9593\u7684\u300c\u5dee\u7570\u300d\u3002</p> <p>Pullback \u5229\u7528 \\(f\\) \u5c07\u8f38\u51fa\u7a7a\u9593 \\(\\mathcal{X}\\) \u7684\u5ea6\u91cf\u898f\u5247\u642c\u56de\u6f5b\u5728\u7a7a\u9593 \\(\\mathcal{Z}\\)\uff0c \u4f7f\u5f97\u5728 \\(\\mathcal{Z}\\) \u4e2d\u7684\u6bcf\u500b\u9ede \\(z\\) \u7684\u5c0f\u4f4d\u79fb\uff08\u5207\u5411\u91cf\uff09\u4e5f\u80fd\u4f9d\u300c\u5c0d\u8f38\u51fa\u9020\u6210\u7684\u5be6\u969b\u8b8a\u5316\u300d\u4f86\u5ea6\u91cf\u3002</p> <p>\u82e5\u8f38\u51fa\u7a7a\u9593 \\(\\mathcal{X}\\) \u4f7f\u7528\u6a19\u6e96\u5167\u7a4d\uff0c\u5247\u5728\u6f5b\u5728\u7a7a\u9593 \\(\\mathcal{Z}\\) \u5b9a\u7fa9\u7684\u62c9\u56de\u5ea6\u91cf\u53ef\u4ee5\u5beb\u6210\uff1a</p> \\[G(z) = J_f(z)^T J_f(z)\\] <p>\u5176\u4e2d \\(J_f(z)\\) \u662f \\(f\\) \u5728\u9ede \\(z\\) \u7684 Jacobian\u3002</p> <p>\u6240\u4ee5\uff0c\u6f5b\u5728\u7a7a\u9593 \\(\\mathcal{Z}\\) \u88e1\u7684\u4e00\u5c0f\u6b65 \\(dz\\) \u7684\u9577\u5ea6\u7531\u8a72\u9ede\u5728\u8f38\u51fa\u7a7a\u9593 \\(\\mathcal{X}\\) \u7684\u5f71\u97ff \\(J_f(z) dz\\) \u7684\u6b50\u6c0f\u8ddd\u96e2\u6240\u63cf\u8ff0\uff1a</p> \\[\\|dz\\|_{G(z)} = \\|J_f(z) dz\\|_2\\] <p>\u8a9e\u7fa9\u6539\u8b8a\u5927\u7684\u65b9\u5411\u6839\u64da pullback metric \u91cf\u6e2c\u7684\u8ddd\u96e2\u5c31\u8f03\u9577\u3002</p>","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#2","title":"2. \u6b63\u5f0f\u5b9a\u7fa9","text":"<p>\u8a2d \\(f : (M, -) \\to (N, g_N)\\) \u70ba\u5149\u6ed1\u6620\u5c04\uff1b\\(g_N\\) \u662f\u76ee\u6a19\u6d41\u5f62 \\(N\\) \u4e0a\u7684 Riemann metric\u3002 Pullback metric\uff08\u8a18\u70ba \\(f^* g_N\\)\uff09\u662f\u5728 \\(M\\) \u4e0a\u7684\u65b0\u5ea6\u91cf\uff0c\u5c0d\u4efb\u610f \\(p\\in M\\) \u53ca\u5207\u5411\u91cf \\(u,v \\in T_p M\\) \u5b9a\u7fa9\uff1a</p> \\[(f^* g_N)_p(u,v) = g_N\\big(f(p)\\big)\\big( (Df)_p(u), (Df)_p(v) \\big)\\] <p>\u5373\uff1a\u5148\u900f\u904e Jacobian \u5c07 \\((u, v)\\) \u63a8\u9001\u5230 \\(N\\) \u7684\u5207\u7a7a\u9593\uff0c\u518d\u7528\u65e2\u6709\u5ea6\u91cf\u91cf\u6e2c\u3002\u9019\u7a2e\u300c\u5c07\u7d50\u69cb\u5f9e\u76ee\u6a19\u7a7a\u9593\u5e36\u56de\u4f86\u6e90\u7a7a\u9593\u300d\u7684\u666e\u904d\u64cd\u4f5c\u7a31\u70ba pullback\uff08\u5c0d\u5076\u64cd\u4f5c\u662f pushforward \u5c07\u5411\u91cf\u9001\u5f80\u76ee\u6a19\uff09\u3002</p> <p>\u82e5 \\(N = \\mathbb{R}^m\\) \u4e14\u63a1\u7528\u6a19\u6e96\u5167\u7a4d \\(\\langle a,b \\rangle = a^T b\\)\uff0c\u5247\uff1a</p> \\[(f^* g_{\\text{Euc}})_p(u,v) = \\langle J_f(p) u, J_f(p) v \\rangle = u^T (J_f(p)^T J_f(p)) v\\]","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#3-vae","title":"3. \u5728 VAE \u4ee5\u53ca\u5176\u4ed6\u751f\u6210\u6a21\u578b\u4e2d\u7684\u8a9e\u610f\u7a7a\u9593","text":"<p>\u5c0d\u4e00\u500b VAE \u4f86\u8aaa\uff0cdecoder \\(f\\) \u5c07\u6f5b\u5728\u5411\u91cf \\(z\\) \u6620\u5c04\u70ba\u5716\u7247\uff08\u8cc7\u6599\uff09 \\(x = f(z)\\)\u3002 \u900f\u904e pullback\uff0c\u65bc\u6bcf\u500b \\(z\\) \u5f97\u5230\u5c0d\u7a31\u6b63\u534a\u5b9a\u77e9\u9663\uff1a</p> \\[G(z) = J_f(z)^T J_f(z)\\] <p>\u5176\u8a98\u5c0e (induced) \u7684\u5167\u7a4d\u8207\u9577\u5ea6\uff1a</p> \\[\\|u\\|_{G(z)} = \\sqrt{u^T G(z) u} = \\|J_f(z) u\\|_2\\] <p>\u5c0d\u8f38\u51fa\u5f71\u50cf \\(x\\) \u9020\u6210\u5927\u6539\u8b8a\u7684\u6f5b\u5728\u65b9\u5411 \\(dz\\) \u88ab\u8ce6\u4e88\u8f03\u5927\u9577\u5ea6\uff0c \u7576\u6211\u5011\u9078\u64c7\u6cbf\u8457 geodesic \uff08\u6e2c\u5730\u7dda\uff0c\u6700\u77ed\u66f2\u7dda\uff09\u884c\u8d70\u6642\uff0c geodesic \u50be\u5411\u907f\u958b\u8a9e\u7fa9\u8df3\u8e8d\u6216\u662f\u4e0d\u9023\u8cab\u7684\u65b9\u5411\uff0c \u56e0\u800c\u7522\u751f\u66f4\u5e73\u6ed1\u3001\u8a9e\u7fa9\u9023\u7e8c\u7684\u63d2\u503c\u3002</p>","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#4","title":"4. \u5178\u578b\u4f8b\u5b50","text":"","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#41","title":"4.1 \u66f2\u7dda\u53c3\u6578\u5316","text":"<p>\u5c0d\u65bc\u4e00\u500b\u55ae\u4f4d\u5713\u66f2\u7dda\u7684\u53c3\u6578 \\(t\\)\uff0c\u6211\u5011\u53ef\u4ee5\u628a\u5b83\u770b\u4f5c\u70ba\u4e00\u500b embedding \u3002 \u5c0d\u65bc\u9019\u500b\u6f5b\u7a7a\u9593\uff0c\u6211\u5011\u53ef\u4ee5\u5b9a\u7fa9 projection \uff1a</p> \\[f : [0,2\\pi) \\to \\mathbb{R}^2\\] \\[f(t) = (\\cos t, \\sin t)\\] <p>Projection \\(f\\) \u5c07\u4e00\u7dad\u53c3\u6578\u7e5e\u6210\u5e73\u9762\u55ae\u4f4d\u5713\u3002</p> <p>\u4ed6\u7684 Jacobian \u53ef\u4ee5\u5beb\u6210\u4e00\u500b 2x1 \u7684\u77e9\u9663\uff1a</p> \\[J_f(t) = \\begin{bmatrix}-\\sin t \\\\ \\cos t \\end{bmatrix}\\] <p>\u56e0\u6b64\u53ef\u4ee5\u7b97\u51fa\u4ed6\u7684 pullback metric \u70ba\uff1a</p> \\[G(t) = J_f(t)^T J_f(t)\\] \\[= \\begin{bmatrix}-\\sin t &amp; \\cos t\\end{bmatrix} \\begin{bmatrix}-\\sin t \\\\ \\cos t \\end{bmatrix}\\] \\[= \\sin^2 t + \\cos^2 t = 1\\] <p>\u56e0\u70ba\u53c3\u6578\u7a7a\u9593\u662f\u4e00\u7dad\uff0c\u56e0\u6b64 metric \u662f\u4e00\u500b\u7d14\u91cf\u3002</p> <p>\u5e7e\u4f55\u610f\u7fa9\uff1a</p> <ol> <li>\u53c3\u6578 \\(t\\) \u5df2\u7d93\u662f\u5f27\u9577\u53c3\u6578\uff08arc-length parameterization\uff09\uff0c\u6545\u55ae\u4f4d\u7684 \\(dt\\) \u76f4\u63a5\u5c0d\u61c9\u5713\u4e0a\u9577\u5ea6 \\(ds=dt\\)\u3002</li> <li>\u8def\u5f91\u9577\u5ea6 \\(L = \\int_a^b \\sqrt{G(t)} dt = b-a\\) \u3002</li> <li>\u6c92\u6709\u5c3a\u5ea6\u626d\u66f2\uff0c\u66f2\u7dda\u4e0a\u4efb\u4f55\u5730\u65b9\u7684\u53c3\u6578\u6b65\u9577\u90fd\u4ee3\u8868\u540c\u6a23\u7684\u5be6\u969b\u5f27\u9577\u3002</li> </ol> <p>\u8a0e\u8ad6\uff1a</p> <ul> <li>\u9019\u500b\u53c3\u6578\u5316\u672c\u8eab\u5df2\u7d93\u5747\u52fb\u7b49\u901f\u7684\u904d\u6b77\u55ae\u4f4d\u5713\uff0c\u6240\u4ee5 \\(G(t)\\) \u4f7f\u4e00\u500b\u4e0d\u4f9d\u8cf4 \\(t\\) \u7684\u51fd\u6578\u3002</li> <li>\u82e5\u6539\u6210 \\(f(t) = (\\cos t^2, \\sin t^2)\\) \u5247 \\(G(t)=4 t^2\\) \uff0c pullback \u6703\u53cd\u6620\u975e\u5747\u52fb\u901f\u5ea6\u3002</li> <li>\u4e00\u7dad\u60c5\u6cc1\u4e0b pullback metric \u5c31\u662f\u66f2\u7dda\u901f\u5ea6\u5e73\u65b9\uff0c\u901f\u5ea6\u662f\u4e00\u500b\u5e38\u6578\u4ee3\u8868 metric \u662f\u4e00\u500b\u5e38\u6578\u3002</li> </ul>","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#42","title":"4.2 \u7403\u9762\u53c3\u6578\u5316","text":"<p>\u5c0d\u65bc\u4e00\u500b\u6a19\u6e96\u55ae\u4f4d\u7403\u9762 \\(S^2\\) \u7684\u53c3\u6578\u5316\uff1a</p> \\[f(\\theta,\\phi) = (\\sin\\theta\\cos\\phi, \\sin\\theta\\sin\\phi, \\cos\\theta)\\] \\[\\theta\\in[0,\\pi], \\quad \\phi\\in[0,2\\pi)\\] <p>\\(\\theta\\) \u70ba\u6975\u89d2\uff08colatitude\uff09\uff0c\\(\\phi\\) \u70ba\u65b9\u4f4d\u89d2\uff08longitude\uff09\u3002</p> <p>\u4ed6\u7684 Jacobian \u53ef\u4ee5\u5beb\u6210\u4e00\u500b 3\u00d72 \u7684\u77e9\u9663\uff0c\u6b64\u6642\u4ed6\u4f5c\u7528\u7684\u662f\u4e00\u500b\u4e8c\u7dad\u5411\u91cf \\(\\begin{bmatrix}\\theta &amp; \\phi\\end{bmatrix}\\)</p> \\[ J_f(\\theta,\\phi)=\\begin{bmatrix} \\cos\\theta\\cos\\phi &amp; -\\sin\\theta\\sin\\phi \\\\ \\cos\\theta\\sin\\phi &amp; \\sin\\theta\\cos\\phi \\\\ -\\sin\\theta &amp; 0 \\end{bmatrix} \\] <p>\u8a08\u7b97\u4ed6\u7684 pullback metric \\(G = J_f^T J_f\\)\uff0c\u53ef\u4ee5\u5f97\u5230\u7d93\u5178\u7403\u9762\u7b2c\u4e00\u57fa\u672c\u5f62\u5f0f\uff1a</p> \\[G(\\theta,\\phi)=\\begin{bmatrix}1 &amp; 0 \\\\ 0 &amp; \\sin^2\\theta\\end{bmatrix}\\] <p>\u5176\u4e2d\uff1a \\(\\langle \\partial_\\theta f, \\partial_\\theta f\\rangle=1\\)\uff0c \\(\\langle \\partial_\\phi f, \\partial_\\phi f\\rangle=\\sin^2\\theta\\)\uff0c \\(\\langle \\partial_\\theta f, \\partial_\\phi f\\rangle=0\\)\u3002</p> <p>\u5e7e\u4f55\u610f\u7fa9\uff1a</p> <ol> <li>\u5fae\u7dda\u5143\u7d20 \\(ds^2 = d\\theta^2 + \\sin^2\\theta d\\phi^2\\)\u3002</li> <li>\u7def\u5ea6\u5708\u534a\u5f91\u70ba \\(\\sin\\theta\\)\uff1a\u8d8a\u9760\u8fd1\u5169\u6975\uff08\\(\\theta \\to 0,\\pi\\)\uff09\u6cbf \\(\\phi\\) \u65b9\u5411\u7684\u5be6\u969b\u8ddd\u96e2\u8d8a\u5c0f\u3002</li> <li>\u53c3\u6578\u5316\u662f\u6b63\u4ea4\u7684\uff08\u7121\u4ea4\u53c9\u9805\uff09\uff0c\u6545\u5fae\u9762\u5143\u7d20 \\(dA = \\sin\\theta\\, d\\theta d\\phi\\)\u3002</li> </ol> <p>\u8a0e\u8ad6\uff1a</p> <ul> <li>\u6b64\u53c3\u6578\u7cfb\u7d71\u672c\u8eab\u662f\u6b63\u4ea4\u5ea7\u6a19\uff0c\u6240\u4ee5\u6c92\u6709\u4ea4\u53c9\u9805\u3002</li> <li>\u53ef\u7528 \\(\\sin^2\\phi\\) \u55ce\uff1f\u4e0d\u884c\uff0c\u56e0\u70ba\u7e2e\u653e\u4f86\u81ea\u7def\u5ea6\u5708\u534a\u5f91\uff0c\u50c5\u4f9d\u8cf4 \\(\\theta\\)\u3002</li> <li>\u5169\u6975\u300c\u5947\u7570\u300d\u662f\u5750\u6a19\u7cfb\u7d71\u554f\u984c\uff0c\u4e26\u975e\u7403\u9762\u5e7e\u4f55\u672c\u8eab\u9000\u5316\u3002</li> </ul> <p>\u8207 4.1 \u6bd4\u8f03\uff1a</p> \u9762\u5411 \u66f2\u7dda (4.1) \u7403\u9762 (4.2) \u7dad\u5ea6 1 \u2192 2 2 \u2192 3 Jacobian \u5f62\u72c0 2\u00d71 3\u00d72 \u5ea6\u91cf\u5f62\u5f0f \u5e38\u6578 1 \\(\\mathrm{diag}(1,\\sin^2\\theta)\\) \u5747\u52fb\u6027 \u53c3\u6578=\u5f27\u9577 \u7d93\u5ea6\u7684\u7e2e\u653e\u96a8\u8457 \\(\\theta\\) \u6539\u8b8a \u5e7e\u4f55\u73fe\u8c61 \u7b49\u901f\u7e5e\u5713 \u7def\u5ea6\u5708\u6536\u7e2e\u3001\u5169\u6975\u5947\u7570 <p>\u9019\u4f8b\u5b50\u5c55\u793a pullback \u5982\u4f55\u81ea\u52d5\u53cd\u6620\u5c40\u90e8\u6709\u6548\u5c3a\u5ea6\uff0cJacobian \u7684 intrinsics \u672c\u8eab\u5b9a\u7fa9\u4e86\u5c40\u90e8\u5c3a\u5ea6\u3002</p>","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#43-vae","title":"4.3 VAE \u5716\u50cf\u8a9e\u7fa9","text":"<p>\u5728\u67d0\u9ede \\(z\\) \u4e0a\uff0c\u5047\u8a2d\u65b9\u5411 \\(du\\) \u50c5\u6539\u8b8a\u5fae\u5f31\u80cc\u666f\uff0c\u4ee3\u8868 \\(\\|du\\|_G\\) \u5f88\u5c0f\u3002 \u5047\u8a2d\u53e6\u4e00\u500b\u65b9\u5411 \\(dv\\) \u6539\u8b8a\u7269\u4ef6\u985e\u5225\uff0c\u4ee3\u8868 \\(\\|dv\\|_G\\) \u5f88\u5927\uff0c\u8a9e\u610f\u5728\u9019\u500b\u65b9\u5411\u4e0a\u6703\u8b8a\u5316\u5f88\u5927\u3002 \u56e0\u6b64\uff0c\u7576\u6211\u5011\u9078\u64c7\u6cbf\u8457\u6f5b\u7a7a\u9593 \\(\\mathcal{Z}\\) \u4e2d\u7684\u4e00\u500b geodesic \u884c\u8d70\uff0c\u6620\u5c04\u5230\u5716\u50cf\uff08\u8cc7\u6599\uff09\u7a7a\u9593\u4e2d\u5247\u6703\u7dad\u6301\u8a9e\u7fa9\u5e73\u9806\u3002</p>","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#5","title":"5. \u70ba\u4f55\u9700\u8981\u62c9\u56de","text":"<p>\u5982\u679c\u6211\u5011\u76f4\u63a5\u5728\u6f5b\u7a7a\u9593\u4e2d\u7528\u6b50\u6c0f\u8ddd\u96e2\u4f86\u8a08\u7b97\uff0c\u6703\u5ffd\u7565\u8f38\u51fa\u8a9e\u7fa9\u8b8a\u5316\u901f\u7387\u7684\u975e\u5747\u52fb\u6027\u3002\u4f46\u4f7f\u7528 pullback metric \u5247\u53ef\u4ee5\u63d0\u4f9b\uff1a</p> <ol> <li>\u8a9e\u7fa9\u654f\u611f\u7684\u8ddd\u96e2\u51fd\u6578\u3002</li> <li>\u66f4\u5408\u7406\u7684\u63d2\u503c\uff0c\u907f\u514d\u7a7f\u8d8a\u8f38\u51fa\u5927\u5e45\u626d\u66f2\u5340\u57df\u6216\u662f\u8a9e\u610f\u672a\u5b9a\u7fa9\u7684\u5340\u57df\u3002</li> <li>\u53ef\u5c0e\u51fa geodesic \u6700\u77ed\u8def\u5f91\u554f\u984c\u4f86\u5f97\u5230\u4e00\u500b\u5408\u7406\u7684 transition trajectory\uff1a</li> </ol> \\[\\mathrm{Length}(\\gamma) = \\int_0^1 \\sqrt{ \\dot{\\gamma}(t)^T G(\\gamma(t)) \\dot{\\gamma}(t)} dt\\]","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#6-pullback-pushforward","title":"6. Pullback \u8207 Pushforward\uff08\u64cd\u4f5c\u5c0d\u5076\uff09","text":"<ul> <li>Pushforward: \u5c07\u5411\u91cf \\(z\\) \u6620\u5c04\u5230\u76ee\u6a19\u7a7a\u9593\u4e2d\u7684\u8cc7\u6599\u9ede \\(x\\)\u3002</li> </ul> \\[(Df)_p : T_p \\mathcal{Z} \\to T_{f(p)} \\mathcal{X}\\] <ul> <li>Pullback Metric: \u4f7f\u7528 pushforward \u628a\u4f86\u6e90\u5207\u5411\u91cf\u6620\u5230\u76ee\u6a19\u5f8c\uff0c\u7528 \\(g_N\\) \u8a55\u4f30\uff0c\u518d\u628a\u7d50\u679c\u8996\u70ba\u4f86\u6e90\u4e0a\u7684\u5167\u7a4d\u3002</li> </ul> <p>\u5c0d\u5076\u7684\u64cd\u4f5c\u70ba\uff1a\u5411\u91cf \\(z\\) \u88ab pushforward \u6210 \\(x\\)\uff0cmetric \u88ab pullback \u56de\u6f5b\u7a7a\u9593 \\(\\mathcal{Z}\\)\u3002</p>","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"posts/pullback_riemannian_metric/#7-degeneracy-regularization","title":"7. \u9000\u5316\u8207\u6b63\u5247\uff08Degeneracy &amp; Regularization\uff09","text":"<p>\u82e5\u6f5b\u5728\u7a7a\u9593 \\(\\mathcal{Z}\\) \u7684\u7dad\u5ea6 \\(d\\) \u5c0f\u65bc\u76ee\u6a19\u7a7a\u9593 \\(\\mathcal{X}\\) \u7684\u7dad\u5ea6 \\(m\\)\uff0c \\(G(z)\\) \u70ba \\(d \\times d\\) Gram \u77e9\u9663\uff0c\u82e5 \\(J_f\\) \u79e9\u4e0d\u8db3 \\(\\mathrm{rank(J_f(z))} &lt; d\\) \u5247 \\(G\\) \u9000\u5316\u70ba\u534a\u6b63\u5b9a\u77e9\u9663\uff0c\u4e5f\u5c31\u662f\u6703\u51fa\u73fe\u4e00\u6216\u591a\u500b\u300c\u96f6\u7279\u5fb5\u503c\u300d\uff0c\u8868\u793a\u8cc7\u8a0a\u647a\u758a\u3002 \u51fa\u73fe\u96f6\u7279\u5fb5\u503c\u610f\u5473\u8457\u5728\u90a3\u4e9b\u65b9\u5411\u4e0a\uff0c\u6f5b\u5728\u7a7a\u9593\u7684\u5c0f\u8b8a\u52d5 \\(dz\\) \u5e7e\u4e4e\u4e0d\u6703\u5728\u8f38\u51fa\u7a7a\u9593\u9020\u6210\u8b8a\u5316\u3002 \u63db\u53e5\u8a71\u8aaa\uff0c\u9019\u4e9b\u65b9\u5411\u5c0d\u61c9\u7684\u662f\u300c\u7121\u8cc7\u8a0a\u65b9\u5411\u300d\u6216\u300c\u5197\u9918\u65b9\u5411\u300d\u3002 \u5728 geodesic \u6700\u4f73\u5316\u6642\uff0c\u9019\u6a23\u7684\u96f6\u7279\u5fb5\u503c\u6703\u9020\u6210\uff1a</p> <ol> <li>\u9023\u7e8c geodesic ODE \u53ef\u80fd\u75c5\u614b\u3002</li> <li>\u8dd1\u6700\u77ed\u8def\u6642\u6703\u51fa\u73fe\u300c\u96f6\u6210\u672c\u300d\u65b9\u5411\uff08\u4e0d\u7a69\u5b9a\uff09\uff0c\u512a\u5316\u6642\u53ef\u80fd\u50be\u5411\u5728\u9019\u4e9b\u65b9\u5411\u300c\u4e82\u8dd1\u300d\uff0c\u56e0\u70ba\u5728\u9019\u4e9b\u65b9\u5411\u63a8\u52d5\u4e0d\u6703\u88ab\u61f2\u7f70\uff08\u8ddd\u96e2\u70ba\u96f6\uff09\u3002</li> </ol> <p>\u89e3\u6c7a\u65b9\u6848\uff1a</p> <ol> <li>\u52a0 Regularization \uff1a\\(G_{\\varepsilon}(z) = J_f(z)^T J_f(z) + \\varepsilon I\\)\u3002</li> <li>\u7279\u5fb5\u503c\u622a\u65b7\uff1a\u53ea\u4fdd\u7559 \\(\\lambda_i &gt; \\tau\\) \u4e3b\u5b50\u7a7a\u9593\u4f5c\u8ddd\u96e2\u3002</li> <li>\u4ee5\u5716\u8fd1\u4f3c\u53d6\u4ee3\u9023\u7e8c\u512a\u5316\uff0c\u96b1\u5f0f\u907f\u958b\u6578\u503c\u89e3 geodesic ODE\u3002</li> </ol>","tags":["Riemannian Geometry","VAE","Generative Model","Manifold"]},{"location":"projects/","title":"Featured","text":""},{"location":"projects/#projects","title":"Projects","text":""},{"location":"projects/#variational-autoencoder-vae","title":"Variational Autoencoder (VAE)","text":"<p>A tiny variational autoencoder (VAE) model to encode images into latent space for latent diffusion models (LDM) in crunch computing power.</p> <p></p>"},{"location":"projects/#latent-diffusion-model-ldm","title":"Latent Diffusion Model (LDM)","text":"<p>A simplified, home-made diffusion model that can be trained on 5GB VRAM</p> <p> </p>"},{"location":"projects/#rivae-riemannian-geometric-generation-via-epistemic-graphs","title":"RiVAE: Riemannian Geometric Generation via Epistemic Graphs","text":"<p>A novel generative model that leverages Riemannian geometry and epistemic uncertainty to produce high-quality data samples by navigating learned latent manifolds.</p>"},{"location":"projects/diffusion/","title":"Diffusion","text":"","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#diffusion-model","title":"Diffusion Model","text":"<p>A simplified, home-made diffusion model that can be trained on 5GB VRAM</p>","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#repository-private","title":"Repository (private)","text":"","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#implementation","title":"Implementation","text":"<p>This project implements a DDPM training framework that departs from standard latent diffusion pipelines. It integrates a custom VAE architecture with a serpentine sequence-processing module, producing a latent space that is both sharper and less leaky, making it well-suited for iterative denoising and high-fidelity reconstructions.</p>","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#key-features","title":"Key Features","text":"","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#vae-with-localized-and-aligned-latents","title":"VAE with Localized and Aligned Latents","text":"<p>The VAE has been carefully designed to mitigate the blurring and leakage issues common in conventional implementations. Its decoder avoids oversized convolution kernels, which reduces cross-pixel contamination, and the latent-to-pixel mapping is tightly aligned so that each latent feature corresponds to localized structures within the image. To maintain global context without compromising local independence, the encoder incorporates Squeeze-and-Excitation layers. Together, these design choices create a latent space that balances local sharpness with global awareness, providing a clean and reliable foundation for the diffusion process.</p>","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#serpentine-module-sequential-feature-processing","title":"Serpentine Module: Sequential Feature Processing","text":"<p>The serpentine module reshapes latent tensors into sequences to capture directional dependencies across the feature map. By scanning in multiple directions \u2014 horizontal, vertical, and others \u2014 the model can model context beyond what standard grid-based convolutions allow. Padding and reshaping ensure that latent features flow naturally into sequence-processing layers inspired by state-space models (SSMs). This approach provides richer contextual information at lower computational cost than full self-attention mechanisms, while remaining more flexible than conventional CNN architectures.</p>","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#ddpm-in-the-custom-latent-space","title":"DDPM in the Custom Latent Space","text":"<p>Building on these components, the DDPM implementation operates directly within the refined latent space. Forward diffusion and noise scheduling are applied to the latent codes, and the noise-prediction network leverages a UNet backbone enhanced with serpentine layers to model sequential dependencies. During reverse denoising, the cleaner and more structured latent representations from the VAE enable reconstructions with reduced blur compared to typical VAE-based diffusion pipelines.</p>","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#training","title":"Training","text":"<p>Training runs entirely in the VAE latent space: latents are noised with a standard DDPM schedule and a UNet denoiser enhanced with serpentine sequence blocks predicts the noise. The localized, SE-augmented VAE keeps latents sharp and well-aligned, enabling efficient batches without leakage. On an NVIDIA RTX 5060 Laptop GPU, mixed precision (AMP) fits batch size 32 in ~5 GB VRAM. The serpentine modules supply directional context with much lower memory than full self-attention, maintaining high throughput and stable optimization over long runs.</p>","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#result","title":"Result","text":"<p>After over 10,000 iterations, the system demonstrates stable convergence and consistent reconstruction quality. The reduced leakage in the latent space makes the model particularly well-suited for localized editing and inpainting, where maintaining precise alignment between latent codes and pixel space is critical. By combining a localized, SE-augmented VAE with a serpentine sequence module, this project establishes a distinct diffusion framework that emphasizes efficiency, sharpness, and structural fidelity in latent space, positioning it as a flexible foundation for future generative modeling applications.</p> <p></p>","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#noise-schedule","title":"Noise Schedule","text":"<p>This project uses a simple linear noise schedule: betas increase evenly from 1e\u22124 to 2e\u22122 across N\u22121 steps (step 0 represents the original image). At each step in the forward pass, the latent is blended with standard Gaussian noise according to the scheduled factor, gradually fading structure into noise. In the reverse pass, the denoiser removes the predicted noise to reconstruct the previous step\u2019s latent; a small amount of fresh noise is added only when the step index is greater than 1 to keep the process stochastic. This modest schedule is deliberately gentle\u2014easy to optimize, memory\u2011friendly, and sufficient to let the model learn the shape of the signal without washing it out.</p> <p></p>","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#generate-from-random-noise","title":"Generate From Random Noise","text":"<p>Generation starts from pure Gaussian latent noise at the last diffusion step and proceeds backward one step at a time. At each step, the denoiser predicts the noise present in the current latent and removes it, reconstructing the previous step\u2019s latent; a small random perturbation is injected except at the final step to keep sampling diverse. The loop runs from the highest step down to 1, with step 0 representing the clean latent. After the reverse loop finishes, the latent is decoded by the VAE decoder to produce the image. This procedure mirrors the training schedule, but in reverse: from structureless noise to a coherent sample, guided by the learned noise predictor and the gentle linear schedule.</p> Result Process","tags":["Generative Model","Diffusion"]},{"location":"projects/diffusion/#inpainting","title":"Inpainting","text":"<p>Inpainting is executed in the VAE latent space to respect locality and alignment. The original image is encoded once; I take the posterior mean as a clean latent anchor. The binary mask from pixel space is mapped to the latent grid by nearest\u2011neighbor downsampling that matches the encoder\u2019s effective stride (here, stride\u20118), so a masked latent tile corresponds exactly to the intended image region with no fractional overlap.</p> <p>Sampling begins at the last diffusion step: the latent is initialized as random noise everywhere except on the masked (preserve) region, where it is clamped to the encoder mean. The reverse loop then runs from the highest step down to one. At each step, the Serpentine denoiser predicts the noise for the current latent, the diffuser steps back one level, and the masked region is re\u2011clamped to the mean. This simple clamp\u2011and\u2011denoise rhythm prevents information from bleeding across the mask boundary while allowing the unmasked area to evolve toward a coherent fill. A small random perturbation is only injected when the step index is greater than one, preserving diversity without disturbing the final alignment. After the loop, decoding the latent yields the inpainted image; non\u2011masked content is preserved exactly by construction.</p> <p>This behavior hinges on the carefully designed VAE and the chosen latent space: localized features and tight latent\u2011to\u2011pixel alignment allow precise mask mapping, and the decoder\u2019s restrained kernels avoid cross\u2011pixel contamination. Meanwhile, the serpentine sequence module supplies directional context across rows and columns, guiding the fill without washing details over the mask edge.</p> <p>In the first set of examples below, the mask covers the face while the background latents are frozen to the encoder\u2019s mean. The result preserves background textures, lighting, and edges exactly, while the masked facial region is resynthesized to match the scene. Boundary transitions remain clean because masked tiles are re\u2011clamped at every step and the decoder does not spill information across the mask.</p> Original Mask Inpainted Process <p>In the second set, the mask targets the background while faces are preserved. Face latents stay clamped, so identity, expression, and contours are maintained bit\u2011for\u2011bit across the sequence. The model rebuilds the background to harmonize color and illumination with the preserved subject, and the serpentine context helps align large\u2011scale structure without bleeding into facial details.</p> Original Mask Inpainted Process","tags":["Generative Model","Diffusion"]},{"location":"projects/rivae/","title":"RiVAE","text":"","tags":["Generative Model","VAE","Manifold","Geodesic","Riemannian Geometry"]},{"location":"projects/rivae/#rivae","title":"RiVAE","text":"<p>Riemannian Geometric Generation via Epistemic Graphs</p> <p> </p> <p>Instead of sampling from a fixed Gaussian prior \\(z \\sim \\mathcal{N}(0, I)\\), RiVAE generates data by navigating through the learned latent geometry. A well-trained VAE on MNIST defines a 2D latent space, but rather than treating it as flat, I reinterpret it as a Riemannian-like manifold induced by the model\u2019s own epistemic structure \u2014 namely, its local uncertainty and global density.</p>","tags":["Generative Model","VAE","Manifold","Geodesic","Riemannian Geometry"]},{"location":"projects/rivae/#repository-private","title":"Repository (private)","text":"<p>The MNIST dataset in latent space:</p> <p></p> <p>Interactive Visualization</p>","tags":["Generative Model","VAE","Manifold","Geodesic","Riemannian Geometry"]},{"location":"projects/rivae/#epistemic-geometry-in-latent-space","title":"Epistemic Geometry in Latent Space","text":"<p>In the RiVAE framework, every latent coordinate \\(z\\) carries two key epistemic quantities:</p> <ul> <li>Local uncertainty \\(U(z)\\): the posterior variance, describing epistemic noise, indicates whether the existence of the data on this coordinate is making sense.</li> <li>Global density \\(P(z)\\): the log-likelihood under a Gaussian Mixture Model fitted on the latent embeddings. Together they define a surrogate line element: [d\\mathcal{l} = (1 + \\alpha_u u(z) + \\alpha_p p(z)) |z_i - z_j|_2] Where \\(U\\) and \\(P\\) penalize motion toward uncertain or low-density regions.</li> </ul> <p>This metric \u2014 termed UDLD (Uncertainty and Density-aware Latent Distance) \u2014 effectively bends the Euclidean latent space according to the model\u2019s epistemic beliefs.</p>","tags":["Generative Model","VAE","Manifold","Geodesic","Riemannian Geometry"]},{"location":"projects/rivae/#from-metric-to-graph","title":"From Metric to Graph","text":"<p>A k-nearest neighbor (kNN) graph built from UDLD distances discretely approximates the manifold\u2019s chart structure. Edges implicitly align with geodesics because the UDLD penalization discourages connections that cross uncertain or low-density regions \u2014 effectively tracing along the manifold\u2019s high-confidence surface.</p> <p></p> <p>Interactive Visualization</p> <p>However, unlike deterministic geodesic solvers, this graph-based construction enables non-deterministic trajectory generation. At each step, the model can probabilistically select the next node among the top-k neighbors, with transition probabilities biased by edge weights or curvature penalties. Thus, trajectories through latent space become stochastic realizations of geodesic motion \u2014 a diffusion-like walk across epistemic geometry, not merely interpolation.</p>","tags":["Generative Model","VAE","Manifold","Geodesic","Riemannian Geometry"]},{"location":"projects/rivae/#local-approximation-over-global-computation","title":"Local Approximation over Global Computation","text":"<p>Because full pairwise UDLD computation scales as \\(O(N^2)\\), direct distance matrices are infeasible for large datasets. Instead, RiVAE employs a sampled-batch approximation, computing local UDLD neighborhoods within limited subsets while always including the start and target points. This is not merely a computational trick \u2014 it echoes how continuous geodesics are integrated locally: dense local information near the current region of interest suffices to maintain global consistency of the path.</p>","tags":["Generative Model","VAE","Manifold","Geodesic","Riemannian Geometry"]},{"location":"projects/rivae/#geometric-generation","title":"Geometric Generation","text":"<p>Once the kNN graph is constructed, generation proceeds as a geodesic walk between latent points. Each intermediate latent code is decoded into an image, yielding a smooth semantic trajectory across the manifold. The resulting animation reveals a discrete geodesic on the epistemic manifold \u2014 each frame a valid MNIST digit, transitioning smoothly in semantic space without leaving the data support.</p> <p></p> <p>Interactive Visualization</p> Start End Transition <p>Such non-deterministic paths can represent families of valid interpolations, sampling multiple epistemically consistent routes between two data modes.</p>","tags":["Generative Model","VAE","Manifold","Geodesic","Riemannian Geometry"]},{"location":"projects/rivae/#outlook","title":"Outlook","text":"<p>RiVAE transforms a conventional VAE into a geometric generator, embedding epistemic awareness directly into the latent topology. Beyond smooth generation, this opens possibilities for:</p> <ul> <li>Curvature-aware latent regularization</li> <li>Geodesic gradient flows</li> <li>Uncertainty-weighted exploration in diffusion models.</li> </ul> <p>Future work may generalize this to higher-dimensional latent spaces by learning Riemannian metrics directly via pullback Jacobians or graph Laplacians \u2014 bridging epistemic geometry and intrinsic generative control.</p>","tags":["Generative Model","VAE","Manifold","Geodesic","Riemannian Geometry"]},{"location":"projects/vae/","title":"VAE","text":"","tags":["VAE","Generative Model","Diffusion"]},{"location":"projects/vae/#variational-autoencoder-vae","title":"Variational Autoencoder (VAE)","text":"<p>A tiny variational autoencoder (VAE) model to encode images into latent space for latent diffusion models (LDM) in crunch computing power.</p>","tags":["VAE","Generative Model","Diffusion"]},{"location":"projects/vae/#repository-private","title":"Repository (private)","text":"","tags":["VAE","Generative Model","Diffusion"]},{"location":"projects/vae/#implementation","title":"Implementation","text":"<p>In this implementation, I designed the vae using three residual blocks for both encoder and decoder.</p> <pre><code>graph LR\n    Images[Images]--&gt; E0(Lift)\n    E0(Lift) --&gt; E1(Res0) --&gt; E2(Res1) --&gt; E3(Res2)\n    E3(Res2) --&gt; E4Mean(Linear) --&gt; Mean[Mean] --&gt; Sample(Sample)\n    E3(Res2) --&gt; E4Var(Linear) --&gt; Var[Var] --&gt; Sample(Sample)\n    Sample(Sample) --&gt; Embedding[Embedding]</code></pre> <pre><code>graph LR\n    Embedding[Embedding] --&gt; D4(Lift)\n    D4(Lift) --&gt; D3(Res2) --&gt; D2(Res1) --&gt; D1(Res0)\n    D1(Res0) --&gt; D0(Project) --&gt; Reconstructed</code></pre> <p>In the encoder, I also added the squeeze-and-excitation mechanism in the trunk of the residual blocks to enhance the ability of feature extraction without dramatically increasing computational resources like attention does.</p>","tags":["VAE","Generative Model","Diffusion"]},{"location":"projects/vae/#training","title":"Training","text":"<p>The pre-trained model on FFHQ 256x256 dataset can be found here. I use NVIDIA TITAN Xp with 12GB VRAM to train the model. And use the mixed precision techniques with batch size <code>28</code> to maximize the usage of VRAM. The learning rate is scheduled from <code>1e-4</code> to <code>0</code> using a cosine annealing schedule.</p>","tags":["VAE","Generative Model","Diffusion"]},{"location":"projects/vae/#result","title":"Result","text":"<p>The VAE is training on FFHQ 256x256 dataset</p> Original Reconstructed","tags":["VAE","Generative Model","Diffusion"]},{"location":"projects/vae/#mask","title":"Mask","text":"<p>To enable inpainting with LDM, the encoder and decoder in this VAE are carefully designed so that a mask in pixel space can be easily mapped into latent space using simple steps like interpolation. The decoder is able to understand masked images in latent space and can reconstruct the image correctly for both masked and unmasked areas in pixel space.</p> Original Target Masked In Latent Space","tags":["VAE","Generative Model","Diffusion"]}]}